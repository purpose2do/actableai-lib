{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data import DataFrame\n",
    "from actableai.data_imputation.error_detector import NullDetector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenj/Documents/Coding/actableai/data_imputation/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/home/chenj/Documents/Coding/actableai/data_imputation/data/data_frame.py:25: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self._fix_strategy = {col: FixStrategy.UNDECIDED for col in df.columns}\n"
     ]
    }
   ],
   "source": [
    "BROKEN_CSV = \"../experiments/data/adult/adult_drop.csv\"\n",
    "\n",
    "df = DataFrame(BROKEN_CSV)\n",
    "\n",
    "errors = df.detect_error(NullDetector())\n",
    "\n",
    "# df.column_types, errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenj/Documents/Coding/actableai/data_imputation/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('age', <ColumnType.Integer: 'integer'>), ('workclass', <ColumnType.Category: 'category'>), ('fnlwgt', <ColumnType.Integer: 'integer'>), ('education', <ColumnType.Category: 'category'>), ('education_num', <ColumnType.Integer: 'integer'>), ('marital_status', <ColumnType.Category: 'category'>), ('occupation', <ColumnType.Category: 'category'>), ('relationship', <ColumnType.Category: 'category'>), ('race', <ColumnType.Category: 'category'>), ('sex', <ColumnType.Category: 'category'>), ('capital_gain', <ColumnType.Integer: 'integer'>), ('capital_loss', <ColumnType.Integer: 'integer'>), ('hours_per_week', <ColumnType.Integer: 'integer'>), ('native_country', <ColumnType.Category: 'category'>), ('salary', <ColumnType.Category: 'category'>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.column_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenj/Documents/Coding/actableai/data_imputation/data/data_frame.py:25: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self._fix_strategy = {col: FixStrategy.UNDECIDED for col in df.columns}\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_181721/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_181721/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    910\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 65) unique label values:  [39.0, 50.0, 53.0, 28.0, 49.0, 52.0, 31.0, 42.0, 37.0, 30.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 4 to avoid cutting too many classes.\n",
      "Warning: Updated holdout_frac from 0.2 to 0.251 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 4 examples. AutoGluon will only keep 50 out of 65 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 4 examples that will be kept for training models: 0.9769230769230769\n",
      "Train Data Class Count: 50\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20707.3 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'salary', 'education_num', 'capital_gain', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'salary', 'education_num', 'capital_gain', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.251, Train Rows: 665, Val Rows: 224\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.0223\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.0357\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "/home/chenj/Documents/Coding/actableai/data_imputation/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "No improvement since epoch 5: early stopping\n",
      "\t0.0893\t = Validation accuracy score\n",
      "\t1.15s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.0848\t = Validation accuracy score\n",
      "\t3.03s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.0848\t = Validation accuracy score\n",
      "\t3.5s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.058\t = Validation accuracy score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.0536\t = Validation accuracy score\n",
      "\t0.57s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.0938\t = Validation accuracy score\n",
      "\t3.1s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.0536\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.0402\t = Validation accuracy score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.0804\t = Validation accuracy score\n",
      "\t3.65s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.0804\t = Validation accuracy score\n",
      "\t20.26s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1161\t = Validation accuracy score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 40.07s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_181721/\")\n",
      "Fixing column: workclass use strategy FixStrategy.AUTOGLUON....\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_181801/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_181801/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    922\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\t6 unique label values:  [6.0, 5.0, 3.0, 2.0, 1.0, 4.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19993.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 737, Val Rows: 185\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.7081\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.6757\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7243\t = Validation accuracy score\n",
      "\t0.99s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBMXT ...\n",
      "\t0.7514\t = Validation accuracy score\n",
      "\t0.84s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.7459\t = Validation accuracy score\n",
      "\t0.91s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7405\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7405\t = Validation accuracy score\n",
      "\t0.6s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.7459\t = Validation accuracy score\n",
      "\t0.41s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7514\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7514\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7351\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.7459\t = Validation accuracy score\n",
      "\t3.42s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7514\t = Validation accuracy score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.98s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_181801/\")\n",
      "Fixing column: fnlwgt use strategy FixStrategy.AUTOGLUON....\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_181812/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_181812/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    915\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1033222.0, 21174.0, 192108.16175, 108165.0673)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20004.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 732, Val Rows: 183\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-110211.8274\t = Validation root_mean_squared_error score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-112396.3222\t = Validation root_mean_squared_error score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-98920.8972\t = Validation root_mean_squared_error score\n",
      "\t0.3s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-99022.4789\t = Validation root_mean_squared_error score\n",
      "\t0.21s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-110201.6721\t = Validation root_mean_squared_error score\n",
      "\t0.46s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-99173.6\t = Validation root_mean_squared_error score\n",
      "\t0.07s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-103703.4612\t = Validation root_mean_squared_error score\n",
      "\t0.49s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-215870.8152\t = Validation root_mean_squared_error score\n",
      "\t0.99s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-102435.6612\t = Validation root_mean_squared_error score\n",
      "\t0.14s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-99341.2736\t = Validation root_mean_squared_error score\n",
      "\t0.51s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-98023.3758\t = Validation root_mean_squared_error score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.0s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_181812/\")\n",
      "Fixing column: education use strategy FixStrategy.AUTOGLUON....\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_181816/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_181816/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    896\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 16) unique label values:  [10.0, 12.0, 2.0, 13.0, 7.0, 16.0, 8.0, 6.0, 11.0, 9.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 13 out of 16 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9877232142857143\n",
      "Train Data Class Count: 13\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19994.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 708, Val Rows: 177\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.2147\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.2429\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7401\t = Validation accuracy score\n",
      "\t1.05s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.9209\t = Validation accuracy score\n",
      "\t2.7s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9379\t = Validation accuracy score\n",
      "\t1.54s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.791\t = Validation accuracy score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7684\t = Validation accuracy score\n",
      "\t0.6s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.9209\t = Validation accuracy score\n",
      "\t1.39s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7684\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7684\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9435\t = Validation accuracy score\n",
      "\t0.56s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9322\t = Validation accuracy score\n",
      "\t5.63s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9492\t = Validation accuracy score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.92s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_181816/\")\n",
      "Fixing column: education_num use strategy FixStrategy.AUTOGLUON....\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_181834/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_181834/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    912\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 16) unique label values:  [13.0, 9.0, 7.0, 14.0, 5.0, 10.0, 12.0, 4.0, 16.0, 11.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 9 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 9 examples. AutoGluon will only keep 14 out of 16 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 9 examples that will be kept for training models: 0.9945175438596491\n",
      "Train Data Class Count: 14\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19980.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'capital_gain', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'capital_gain', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 725, Val Rows: 182\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.2857\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.2418\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7363\t = Validation accuracy score\n",
      "\t1.08s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.8736\t = Validation accuracy score\n",
      "\t2.24s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9121\t = Validation accuracy score\n",
      "\t1.36s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7857\t = Validation accuracy score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8022\t = Validation accuracy score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8846\t = Validation accuracy score\n",
      "\t1.47s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8077\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7967\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9066\t = Validation accuracy score\n",
      "\t0.56s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.8956\t = Validation accuracy score\n",
      "\t5.84s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9176\t = Validation accuracy score\n",
      "\t0.29s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.51s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_181834/\")\n",
      "Fixing column: marital_status use strategy FixStrategy.AUTOGLUON....\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_181850/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_181850/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    903\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\t7 unique label values:  [5.0, 3.0, 4.0, 6.0, 1.0, 2.0, 7.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 6 out of 7 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9988925802879292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19934.7 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 721, Val Rows: 181\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.3923\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.3591\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7735\t = Validation accuracy score\n",
      "\t0.97s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.7845\t = Validation accuracy score\n",
      "\t0.76s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.8122\t = Validation accuracy score\n",
      "\t0.9s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7735\t = Validation accuracy score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.779\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8066\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7845\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7845\t = Validation accuracy score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.8122\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.779\t = Validation accuracy score\n",
      "\t3.22s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8177\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.7s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_181850/\")\n",
      "Fixing column: occupation use strategy FixStrategy.AUTOGLUON....\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_181901/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_181901/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    900\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 14) unique label values:  [1.0, 4.0, 6.0, 10.0, 8.0, 12.0, 14.0, 5.0, 7.0, 13.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 14 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9966666666666667\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19920.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 717, Val Rows: 180\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.0944\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.05\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 4: early stopping\n",
      "\t0.3222\t = Validation accuracy score\n",
      "\t0.86s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.3556\t = Validation accuracy score\n",
      "\t1.22s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.3167\t = Validation accuracy score\n",
      "\t1.9s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.2722\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.2611\t = Validation accuracy score\n",
      "\t0.59s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.3056\t = Validation accuracy score\n",
      "\t0.98s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.2444\t = Validation accuracy score\n",
      "\t0.63s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.2722\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.3056\t = Validation accuracy score\n",
      "\t1.13s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.2722\t = Validation accuracy score\n",
      "\t7.71s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3611\t = Validation accuracy score\n",
      "\t0.3s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.94s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_181901/\")\n",
      "Fixing column: relationship use strategy FixStrategy.AUTOGLUON....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_181919/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_181919/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    902\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\t6 unique label values:  [2.0, 1.0, 6.0, 4.0, 5.0, 3.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19869.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'age', 'salary', 'education_num', 'capital_gain', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'age', 'salary', 'education_num', 'capital_gain', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 721, Val Rows: 181\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.3315\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.2818\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7403\t = Validation accuracy score\n",
      "\t1.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.7459\t = Validation accuracy score\n",
      "\t1.24s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.7403\t = Validation accuracy score\n",
      "\t0.98s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7072\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7293\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.7293\t = Validation accuracy score\n",
      "\t1.04s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6961\t = Validation accuracy score\n",
      "\t0.63s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6961\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7569\t = Validation accuracy score\n",
      "\t0.57s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.7348\t = Validation accuracy score\n",
      "\t3.72s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7624\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.37s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_181919/\")\n",
      "Fixing column: race use strategy FixStrategy.AUTOGLUON....\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_181932/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_181932/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    894\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\t5 unique label values:  [5.0, 3.0, 2.0, 1.0, 4.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 5 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9865771812080537\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19859.45 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 705, Val Rows: 177\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.8249\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.8249\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.8757\t = Validation accuracy score\n",
      "\t0.95s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.8814\t = Validation accuracy score\n",
      "\t0.6s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.904\t = Validation accuracy score\n",
      "\t0.7s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8701\t = Validation accuracy score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8757\t = Validation accuracy score\n",
      "\t0.6s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8701\t = Validation accuracy score\n",
      "\t0.23s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8757\t = Validation accuracy score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8757\t = Validation accuracy score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.8644\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.8757\t = Validation accuracy score\n",
      "\t1.96s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.904\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 8.41s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_181932/\")\n",
      "Fixing column: sex use strategy FixStrategy.NEIGHBOR....\n",
      "Fixing column: capital_gain use strategy FixStrategy.AUTOGLUON....\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_181940/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_181940/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    920\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 30) unique label values:  [0.0, 14084.0, 5178.0, 5013.0, 2407.0, 14344.0, 15024.0, 7688.0, 4064.0, 4386.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 2 to avoid cutting too many classes.\n",
      "Warning: Updated holdout_frac from 0.2 to 0.501 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 2 examples. AutoGluon will only keep 14 out of 30 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 2 examples that will be kept for training models: 0.9826086956521739\n",
      "Train Data Class Count: 14\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19840.7 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.501, Train Rows: 451, Val Rows: 453\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.9382\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.8918\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.8962\t = Validation accuracy score\n",
      "\t0.83s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.9382\t = Validation accuracy score\n",
      "\t0.79s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9382\t = Validation accuracy score\n",
      "\t0.98s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9382\t = Validation accuracy score\n",
      "\t0.58s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9382\t = Validation accuracy score\n",
      "\t0.58s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.9382\t = Validation accuracy score\n",
      "\t0.7s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9382\t = Validation accuracy score\n",
      "\t0.58s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9382\t = Validation accuracy score\n",
      "\t0.57s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9404\t = Validation accuracy score\n",
      "\t0.45s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9382\t = Validation accuracy score\n",
      "\t3.13s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9404\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.61s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_181940/\")\n",
      "Fixing column: capital_loss use strategy FixStrategy.AUTOGLUON....\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_181951/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_181951/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    903\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 30) unique label values:  [0.0, 2042.0, 1408.0, 1902.0, 1887.0, 1762.0, 1564.0, 2179.0, 1816.0, 1980.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 2 to avoid cutting too many classes.\n",
      "Warning: Updated holdout_frac from 0.2 to 0.501 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 2 examples. AutoGluon will only keep 10 out of 30 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 2 examples that will be kept for training models: 0.9778516057585825\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19846.95 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatically generating train/validation split with holdout_frac=0.501, Train Rows: 440, Val Rows: 443\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.9639\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.9616\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9278\t = Validation accuracy score\n",
      "\t0.82s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.9639\t = Validation accuracy score\n",
      "\t0.53s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9639\t = Validation accuracy score\n",
      "\t0.64s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9639\t = Validation accuracy score\n",
      "\t0.56s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9639\t = Validation accuracy score\n",
      "\t0.56s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.9639\t = Validation accuracy score\n",
      "\t0.53s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9639\t = Validation accuracy score\n",
      "\t0.57s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9639\t = Validation accuracy score\n",
      "\t0.57s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9639\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9661\t = Validation accuracy score\n",
      "\t2.6s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9661\t = Validation accuracy score\n",
      "\t0.29s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9.15s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_181951/\")\n",
      "Fixing column: hours_per_week use strategy FixStrategy.AUTOGLUON....\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_182000/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_182000/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    901\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 52) unique label values:  [40.0, 13.0, 16.0, 50.0, 80.0, 30.0, 45.0, 35.0, 60.0, 20.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 3 to avoid cutting too many classes.\n",
      "Warning: Updated holdout_frac from 0.2 to 0.3343333333333333 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 3 examples. AutoGluon will only keep 34 out of 52 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 3 examples that will be kept for training models: 0.97669256381798\n",
      "Train Data Class Count: 34\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19834.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.3343333333333333, Train Rows: 585, Val Rows: 295\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.3661\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.2915\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.4373\t = Validation accuracy score\n",
      "\t1.19s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.4915\t = Validation accuracy score\n",
      "\t2.49s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.4915\t = Validation accuracy score\n",
      "\t3.2s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.4678\t = Validation accuracy score\n",
      "\t0.63s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.4814\t = Validation accuracy score\n",
      "\t0.59s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.4915\t = Validation accuracy score\n",
      "\t1.69s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.4814\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.4712\t = Validation accuracy score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.4881\t = Validation accuracy score\n",
      "\t1.64s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.4915\t = Validation accuracy score\n",
      "\t11.49s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4949\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 25.99s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_182000/\")\n",
      "Fixing column: native_country use strategy FixStrategy.AUTOGLUON....\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210726_182027/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210726_182027/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    913\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 28) unique label values:  [27.0, 4.0, 16.0, 14.0, 19.0, 23.0, 13.0, 8.0, 2.0, 10.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 3 to avoid cutting too many classes.\n",
      "Warning: Updated holdout_frac from 0.2 to 0.3343333333333333 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 3 examples. AutoGluon will only keep 12 out of 28 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fraction of data from classes with at least 3 examples that will be kept for training models: 0.9759036144578314\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19685.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['sex', 'relationship', 'age', 'salary', 'education_num', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.3343333333333333, Train Rows: 593, Val Rows: 298\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.9362\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.9027\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9262\t = Validation accuracy score\n",
      "\t1.22s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.9396\t = Validation accuracy score\n",
      "\t0.87s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9396\t = Validation accuracy score\n",
      "\t0.98s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9396\t = Validation accuracy score\n",
      "\t0.6s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9396\t = Validation accuracy score\n",
      "\t0.61s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.9396\t = Validation accuracy score\n",
      "\t0.63s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9396\t = Validation accuracy score\n",
      "\t0.6s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9396\t = Validation accuracy score\n",
      "\t0.6s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9396\t = Validation accuracy score\n",
      "\t0.45s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9396\t = Validation accuracy score\n",
      "\t3.48s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9396\t = Validation accuracy score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.3s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210726_182027/\")\n",
      "Fixing column: salary use strategy FixStrategy.NEIGHBOR....\n",
      "/home/chenj/Documents/Coding/actableai/data_imputation/data/data_frame.py:25: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self._fix_strategy = {col: FixStrategy.UNDECIDED for col in df.columns}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'workclass': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'fnlwgt': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'education': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'education_num': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'marital_status': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'occupation': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'relationship': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'race': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'sex': <FixStrategy.NEIGHBOR: 2>,\n",
       " 'capital_gain': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'capital_loss': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'hours_per_week': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'native_country': <FixStrategy.AUTOGLUON: 3>,\n",
       " 'salary': <FixStrategy.NEIGHBOR: 2>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_df = df.auto_fix()\n",
    "\n",
    "fixed_df.to_csv(\"../experiments/data/adult/repaired-from-my.csv\")\n",
    "\n",
    "fixed_df.fix_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenj/Documents/Coding/actableai/data_imputation/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/home/chenj/Documents/Coding/actableai/data_imputation/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/chenj/Documents/Coding/actableai/data_imputation/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Precision:\n",
      "  Holoclean: 0.3535333333333333\n",
      "  My: 0.9646\n",
      "Average Recall:\n",
      "  Holoclean: 0.3530039976711625\n",
      "  My: 0.9028386202723132\n"
     ]
    }
   ],
   "source": [
    "from evaluate import evaluate\n",
    "\n",
    "evaluate(\"adult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}